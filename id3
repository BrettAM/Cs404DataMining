#!/usr/bin/env python3
import sys
import functools
import math

class Feature:
    def __init__(self, args):
        self.name = args[0]
        self.cont = args[1] == "continuous"
        self.values = args[1:] if not self.cont else []
    def __str__(self):
        return self.name
    def __repr__(self):
        return self.name

class LessThanEQ:
    def __init__(self, val):
        self.val = val
        self.ltval = float(val)
    def prompt(self, ans):
        return ("<=" if ans else ">") + str(self.val)
    def __repr__(self):
        return "LessThanEQ({0.val})".format(self)
    def __str__(self):
        return "<={0.ltval}".format(self)
    def __call__(self,x):
        return float(x) <= self.ltval

class Identity:
    def prompt(self, ans):
        return "="+ans
    def __repr__(self):
        return "Identity()"
    def __str__(self):
        return "="
    def __call__(self, x):
        return x
ident = Identity()

class Classifier:
    def __init__(self, key, by=ident):
        self.key = key
        self.by  = by
    def prompt(self, ans):
        return "{0}{1}:".format(self.key, self.by.prompt(ans))
    def __repr__(self):
        return "Classifier({0.key}, {1})".format(self, repr(self.by))
    def __str__(self):
        return "{0.key}{0.by}".format(self)
    def __call__(self, caseDict):
        return self.by(caseDict.get(self.key, None))
    def __eq__(self, y):
        return self.key == y.key and self.by == y.by
    def filter(self, dataset):
        """ Filter this key out of a dataset """
        newds = dataset.copy()
        del newds[self.key]
        return newds
    def values(self):
        """ List the possible values """
        if self.by is ident:
            return self.key.values
        else:
            return [True, False]

def entropy(occurances):
    """ Calculate the entropy represented by an list of occurance counts """
    total = sum(occurances)
    if total == 0:
        return 0.0 # change to math.inf to disallow empty partitions
    probability = map(lambda c: c/total, occurances)
    return sum([-p*math.log2(p) for p in probability if p!=0.0])

def setEntropy(dataset, Classifier):
    """ Calculate the entropy in the data after dividing input by Classifier """
    return entropy([len(v) for v in splitDataset(dataset, Classifier).values()])

def splitDataset(dataset, Classifier):
    """ Return the resulting datasets when input is divided by Classifier """
    def appendCase(d,v):
        k = Classifier(v)
        d[k].append(Classifier.filter(v))
        return d
    emptyMap = {k:[] for k in Classifier.values()}
    return functools.reduce(appendCase, dataset, emptyMap)

def entropyGain(dataset, splitClass, entroClass):
    """ the entropy gain WRT entroClass when dataset is split by splitClass """
    splitsets = splitDataset(dataset, splitClass)
    gain = sum([len(s)*setEntropy(s, entroClass) for s in splitsets.values()])
    return gain

def findAllClasses(dataset):
    """ Return a list of all Classifiers applicable to this dataset """
    classes = []
    for f in dataset[0].keys(): #really wish I had flatMap
        if not f.cont:
            classes.append(Classifier(f))
        else:
            values   = [data[f] for data in dataset]
            classes += [Classifier(f, LessThanEQ(v)) for v in values]
    return classes

def id3(dataset, solveFeature):
    if setEntropy(dataset, solveFeature) == 0.0:
        if len(dataset) == 0:
            return [defaultAnswer, []]
        else:
            return (str(solveFeature(dataset[0])), [])
    classes = [c for c in findAllClasses(dataset) if not c == solveFeature]
    classes = [(entropyGain(dataset, c, solveFeature), c) for c in classes]
    classes = [c for c in classes if not math.isnan(c[0])]
    classes.sort(key=lambda c: c[0])

    #print(dataset)
    #for (e,c) in classes:
    #    print(e,c)

    if len(classes) == 0:
        #return (defaultAnswer, [])
        return ("Out of features", [])

    sdata = splitDataset(dataset, classes[0][1])

    #for f,d in sdata.items():
    #    print(f,d)
    #print()

    return (classes[0][1], [(k, id3(v,solveFeature)) for k,v in sdata.items()])

def displayTree(tree, ident):
    question = tree[0]
    if len(tree[1]) == 0: #leaf
        print(" "*ident + question)
    for (ans, nt) in tree[1]:
        print(" "*ident + question.prompt(ans))
        displayTree(nt, ident+4)

#input
def fixHumiTypo(line):
    result = []
    for word in line:
        if word == 'Humi':
            result.append('Humid')
        else:
            result.append(word)
    return result

featureCount = int(input())+1
featureLines = [input().split() for i in range(0, featureCount)]
features = [Feature(l) for l in featureLines]

defaultAnswer = next(x for x in features if x.name == "Ans").values[0]

data = [dict(zip(features, fixHumiTypo(l.split())))
                for l in sys.stdin.readlines()]

result = id3(data, Classifier(features[-1]))
displayTree(result, 0)
